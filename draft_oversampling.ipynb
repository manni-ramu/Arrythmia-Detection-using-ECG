{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07046a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Manni Chellappan\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import pywt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, AvgPool1D, Flatten, Dense, Dropout, Softmax\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1b0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\Manni Chellappan\\\\Arrythmia-Detection-using-ECG\\\\mitbih_database\\\\'\n",
    "classnames = ['N', 'L', 'R', 'A', 'V']\n",
    "n_classes = len(classnames)\n",
    "count_classes = [0]*n_classes\n",
    "\n",
    "X = list()\n",
    "y = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efc9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100.csv', '100annotations.txt', '101.csv', '101annotations.txt', '102.csv', '102annotations.txt', '103.csv', '103annotations.txt', '104.csv', '104annotations.txt', '105.csv', '105annotations.txt', '106.csv', '106annotations.txt', '107.csv', '107annotations.txt', '108.csv', '108annotations.txt', '109.csv', '109annotations.txt', '111.csv', '111annotations.txt', '112.csv', '112annotations.txt', '113.csv', '113annotations.txt', '114.csv', '114annotations.txt', '115.csv', '115annotations.txt', '116.csv', '116annotations.txt', '117.csv', '117annotations.txt', '118.csv', '118annotations.txt', '119.csv', '119annotations.txt', '121.csv', '121annotations.txt', '122.csv', '122annotations.txt', '123.csv', '123annotations.txt', '124.csv', '124annotations.txt', '200.csv', '200annotations.txt', '201.csv', '201annotations.txt', '202.csv', '202annotations.txt', '203.csv', '203annotations.txt', '205.csv', '205annotations.txt', '207.csv', '207annotations.txt', '208.csv', '208annotations.txt', '209.csv', '209annotations.txt', '210.csv', '210annotations.txt', '212.csv', '212annotations.txt', '213.csv', '213annotations.txt', '215.csv', '215annotations.txt', '217.csv', '217annotations.txt', '219.csv', '219annotations.txt', '220.csv', '220annotations.txt', '221.csv', '221annotations.txt', '222.csv', '222annotations.txt', '223.csv', '223annotations.txt', '228.csv', '228annotations.txt', '230.csv', '230annotations.txt', '231.csv', '231annotations.txt', '232.csv', '232annotations.txt', '233.csv', '233annotations.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = next(os.walk(filepath))[2]\n",
    "\n",
    "\n",
    "signaldata = list()\n",
    "annotations = list()\n",
    "filenames.sort()\n",
    "print((filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61977d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filenames:\n",
    "    filename, file_ext = os.path.splitext(f)\n",
    "\n",
    "    if(file_ext == '.csv'):\n",
    "        signaldata.append(filepath + filename + file_ext)\n",
    "\n",
    "    elif(file_ext == '.txt'):\n",
    "        annotations.append(filepath + filename + file_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae81e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3310c2ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m     boolvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     51\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(beat)\n\u001b[1;32m---> 52\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(c_ind)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "window_size = 180\n",
    "for r in range(0, len(signaldata)):\n",
    "    signals = []\n",
    "\n",
    "    with open(signaldata[r], 'rt',) as csvfile:\n",
    "        tempstorage = csv.reader(csvfile, delimiter=',',\n",
    "                                 quotechar='|')\n",
    "        insrtindx = -1\n",
    "        for row in tempstorage:\n",
    "            if(insrtindx >= 0):\n",
    "                signals.insert(insrtindx, int(row[1]))\n",
    "            insrtindx = insrtindx+1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "\n",
    "    if r == 1:\n",
    "        plt_1 = plt.figure(figsize=(30, 6))\n",
    "        plt.grid()\n",
    "\n",
    "        plt.title(signaldata[1] + \" Ecg Wave\")\n",
    "\n",
    "        plt.plot(signals[0:700])\n",
    "        plt.show()\n",
    "        sc=signals\n",
    "\n",
    "    boolvar = False\n",
    "    with open(annotations[r], 'r') as fileID:\n",
    "        data = fileID.readlines()\n",
    "        beat = list()\n",
    "\n",
    "        for d in range(1, len(data)):\n",
    "            splitted = data[d].split(' ')\n",
    "            splitted = filter(None, splitted)\n",
    "            next(splitted)\n",
    "            pos = int(next(splitted))\n",
    "            class_type = next(splitted)\n",
    "            if(class_type in classnames):\n",
    "                c_ind = classnames.index(class_type)\n",
    "\n",
    "                count_classes[c_ind] += 1\n",
    "                if(window_size <= pos and pos < (len(signals) - window_size)):\n",
    "                    beat = signals[pos-window_size:pos+window_size]\n",
    "                    if r == 1 and not boolvar:\n",
    "                        plt_1 = plt.figure(figsize=(30, 6))\n",
    "                        plt.grid()\n",
    "                        plt.title(\"A Beat from \" + signaldata[1] + \" Ecg Wave\")\n",
    "                        plt.plot(beat)\n",
    "                        plt.show()\n",
    "                        boolvar = True\n",
    "\n",
    "                    X.append(beat)\n",
    "                    y.append(c_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ede01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(X)):\n",
    "        X[i] = np.append(X[i], y[i])\n",
    "\n",
    "print(np.shape(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856239ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X)\n",
    "per_class = X_train_df[X_train_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "explode=(0,0.1,0.1,0.1,0.1)\n",
    "plt.pie(per_class, labels=['Non-ectopic Beats', 'Left Bundle Branch Block', 'Right Bundle Branch Block', 'Atrial Premature Contraction', 'Premature Ventricular Contraction'],explode=explode, colors=['tab:blue','tab:orange','tab:purple','tab:red','tab:green'],autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_df.iloc[:, :-1]\n",
    "y = X_train_df.iloc[:, -1]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "class_dist = pd.Series(y_sm).value_counts()\n",
    "print(class_dist)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.pie(class_dist, labels=le.classes_, colors=['tab:blue','tab:orange','tab:purple','tab:red','tab:green'],autopct='%1.1f%%')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(X_train_df, test_size=0.20,random_state=45637)\n",
    "\n",
    "print(\"X_train : \", np.shape(train))\n",
    "print(\"X_test  : \", np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train[train.shape[1]-1]\n",
    "target_test=test[test.shape[1]-1]\n",
    "train_y=to_categorical(target_train)\n",
    "test_y=to_categorical(target_test)\n",
    "print(np.shape(train_y), np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbad694",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:,:train.shape[1]-1].values\n",
    "test_x = test.iloc[:,:test.shape[1]-1].values\n",
    "train_x = train_x.reshape(len(train_x), train_x.shape[1],1)\n",
    "test_x = test_x.reshape(len(test_x), test_x.shape[1],1)\n",
    "print(np.shape(train_x), np.shape(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3454cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=13, padding='same', activation='relu',input_shape=(360, 1)))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=17, padding='same', activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=19, padding='same', activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(35,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dense(5,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Softmax())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c1e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbase = model.fit(train_x, train_y, batch_size=36, epochs=10, verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelecg.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modelbase.history['loss'])\n",
    "plt.plot(modelbase.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db71817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modelbase.history['accuracy'])\n",
    "plt.plot(modelbase.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y)\n",
    "y_pred=model.predict(test_x)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_y.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'L', 'R', 'A', 'V'],normalize=True,\n",
    "                      title='Confusion matrix, with normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "for i in range(0,5):\n",
    "\trandomnum=np.random.randint(1,6456476)\n",
    "\ttrain, test = train_test_split(X_train_df, test_size=0.20,random_state=randomnum)\n",
    "\n",
    "\t\n",
    "\n",
    "\ttarget_train=train[train.shape[1]-1]\n",
    "\ttarget_test=test[test.shape[1]-1]\n",
    "\ttrain_y=to_categorical(target_train)\n",
    "\ttest_y=to_categorical(target_test)\n",
    "\n",
    "\ttrain_x = train.iloc[:,:train.shape[1]-1].values\n",
    "\ttest_x = test.iloc[:,:test.shape[1]-1].values\n",
    "\ttrain_x = train_x.reshape(len(train_x), train_x.shape[1],1)\n",
    "\ttest_x = test_x.reshape(len(test_x), test_x.shape[1],1)\n",
    "\tprint(np.shape(train_x), np.shape(test_x))\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=16, kernel_size=13, padding='same', activation='relu',input_shape=(360, 1)))\n",
    "\tmodel.add(AvgPool1D(pool_size=3, strides=2))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=17, padding='same', activation='relu'))\n",
    "\tmodel.add(AvgPool1D(pool_size=3, strides=2))\n",
    "\tmodel.add(Conv1D(filters=128, kernel_size=19, padding='same', activation='relu'))\n",
    "\tmodel.add(AvgPool1D(pool_size=3, strides=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(35,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "\tmodel.add(Dense(5,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "\tmodel.add(Softmax())\n",
    "# model.summary()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\t# Fit the model\n",
    "\tmodel.fit(train_x, train_y, epochs=10, batch_size=36, verbose=1)\n",
    "\tscores = model.evaluate(test_x, test_y, verbose=1)\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\tcvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3289625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf91bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
